{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f34da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sider\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "server = 'cyse492group8.database.windows.net'\n",
    "database = 'CYSE492_Project'\n",
    "username = 'cyseadmin'\n",
    "password = 'GroupProject492'\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f875b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT [Control Identifier],[Control Text]  FROM [dbo].['NIST_800.53_controls$']\")\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "for row in cursor:\n",
    "    texts.append(row[1])\n",
    "    if 'AC' in row[0]:\n",
    "        labels.append(1)\n",
    "    if 'AT' in row[0]:\n",
    "        labels.append(2)\n",
    "    if 'AU' in row[0]:\n",
    "        labels.append(3)\n",
    "    if 'CA' in row[0]:\n",
    "        labels.append(4)\n",
    "    if 'CM' in row[0]:\n",
    "        labels.append(5)\n",
    "    if 'CP' in row[0]:\n",
    "        labels.append(6)\n",
    "    if 'IA' in row[0]:\n",
    "        labels.append(7)\n",
    "    if 'IR' in row[0]:\n",
    "        labels.append(8)\n",
    "    if 'MA' in row[0]:\n",
    "        labels.append(9)\n",
    "    if 'MP' in row[0]:\n",
    "        labels.append(10)\n",
    "    if 'PE' in row[0]:\n",
    "        labels.append(11)\n",
    "    if 'PL' in row[0]:\n",
    "        labels.append(12)\n",
    "    if 'PM' in row[0]:\n",
    "        labels.append(13)\n",
    "    if 'PS' in row[0]:\n",
    "        labels.append(14)\n",
    "    if 'PT' in row[0]:\n",
    "        labels.append(15)\n",
    "    if 'RA' in row[0]:\n",
    "        labels.append(16)\n",
    "    if 'SA' in row[0]:\n",
    "        labels.append(17)\n",
    "    if 'SC' in row[0]:\n",
    "        labels.append(18)\n",
    "    if 'SI' in row[0]:\n",
    "        labels.append(19)\n",
    "    if 'SR' in row[0]:\n",
    "        labels.append(20)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "x_act = np.array(texts)\n",
    "y_act = np.array(labels)\n",
    "\n",
    "# test is the actual test, act is used for the training\n",
    "for i in range(500):\n",
    "    random_index = random.randrange(len(labels))\n",
    "    x_test.append(texts.pop(random_index))\n",
    "    y_test.append(labels.pop(random_index))\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d69e1b2-0015-497d-b33a-80e8823828d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sider\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sider\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\sider\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sider\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "38/38 [==============================] - 21s 286ms/step - loss: 2.9241 - accuracy: 0.1329\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 10s 267ms/step - loss: 2.6088 - accuracy: 0.2649\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 10s 258ms/step - loss: 2.2130 - accuracy: 0.3701\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 10s 272ms/step - loss: 1.7609 - accuracy: 0.5290\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 10s 249ms/step - loss: 1.3872 - accuracy: 0.6526\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 11s 294ms/step - loss: 1.1013 - accuracy: 0.7620\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 0.8488 - accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 0.6577 - accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 10s 273ms/step - loss: 0.5091 - accuracy: 0.9142\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 10s 273ms/step - loss: 0.5786 - accuracy: 0.8856\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 10s 270ms/step - loss: 0.4086 - accuracy: 0.9352\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 10s 269ms/step - loss: 0.3100 - accuracy: 0.9495\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 10s 263ms/step - loss: 0.2678 - accuracy: 0.9596\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 10s 254ms/step - loss: 0.2072 - accuracy: 0.9680\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 0.1719 - accuracy: 0.9714\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.1700 - accuracy: 0.9714\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.1599 - accuracy: 0.9680\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.1439 - accuracy: 0.9722\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 10s 265ms/step - loss: 0.1212 - accuracy: 0.9781\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 0.1121 - accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "max_words = 15000 # max number of words to use in the vocabulary was 15k\n",
    "max_len = 400 # max length of each text (in terms of number of words) 250\n",
    "embedding_dim = 400 # dimension of word embeddings was 100\n",
    "lstm_units = 32 # number of units in the LSTM layer\n",
    "# num_classes = len(set(labels)) + 1 # number of classes\n",
    "num_classes = len(set(y_act)) + 1 # number of classes\n",
    "#num_classes2 = len(set(y_test)) + 1\n",
    "\n",
    "# Tokenize the texts and create a vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_act)\n",
    "sequences = tokenizer.texts_to_sequences(x_act)\n",
    "\n",
    "# Pad the sequences so they all have the same length\n",
    "x = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "\n",
    "# Create one-hot encoded labels\n",
    "y = keras.utils.to_categorical(y_act, num_classes)\n",
    "\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(lstm_units))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x, y, batch_size=32, epochs=20)# was 32,20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebde3d09-0bd4-49c7-b8ba-b4111da6b3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 69ms/step - loss: 0.0950 - accuracy: 0.9800\n",
      "Test set\n",
      "  Loss: 0.095\n",
      "  Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "###padding\n",
    "## reuse old tokenizer for x_test\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_act)\n",
    "sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "## Pad the sequences so they all have the same length\n",
    "x_test = pad_sequences(sequences, maxlen=max_len)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Test the model     \n",
    "#If you want to test different x_test/y_test you can compile that section instead of retraining the whole thing again\n",
    "accr = model.evaluate(x_test,y_test) #x and y instead of test?\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n",
    "#for i in range(10):\n",
    "#    result = tf.argmax(model.predict(tf.expand_dims(texts[i], 0)), axis=1)\n",
    "#    print(result.numpy(), labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cea26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x_act[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0effd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(y_act)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814349d-9957-4f6c-9ea0-1fc20a06a9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
